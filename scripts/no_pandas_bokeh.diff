diff --git a/src/bokeh/document/events.py b/src/bokeh/document/events.py
index 093a899da..37988e0d0 100644
--- a/src/bokeh/document/events.py
+++ b/src/bokeh/document/events.py
@@ -515,8 +515,11 @@ class ColumnsStreamedEvent(DocumentPatchedEvent):
         self.attr = attr


-        import pandas as pd
-        if isinstance(data, pd.DataFrame):
+        try:
+            import pandas as pd
+        except ImportError:
+            pd = None
+        if pd and isinstance(data, pd.DataFrame):
             data = {c: data[c] for c in data.columns}

         self.data = data
diff --git a/src/bokeh/models/sources.py b/src/bokeh/models/sources.py
index cb6293919..6be5aa2f5 100644
--- a/src/bokeh/models/sources.py
+++ b/src/bokeh/models/sources.py
@@ -230,12 +230,15 @@ class ColumnDataSource(ColumnarDataSource):
         raw_data: DataDict = kwargs.pop("data", {})

         import narwhals.stable.v1 as nw
-        import pandas as pd
+        try:
+            import pandas as pd
+        except ImportError:
+            pd = None

         if not isinstance(raw_data, dict):
             if nw.dependencies.is_into_dataframe(raw_data):
                 raw_data = self._data_from_df(raw_data)
-            elif isinstance(raw_data, pd.core.groupby.GroupBy):
+            elif pd and isinstance(raw_data, pd.core.groupby.GroupBy):
                 raw_data = self._data_from_groupby(raw_data)
             else:
                 raise ValueError(f"expected a dict or eager dataframe support by Narwhals, got {raw_data}")
@@ -542,11 +545,14 @@ class ColumnDataSource(ColumnarDataSource):
             source.stream(new_data)

         '''
-        import pandas as pd
+        try:
+            import pandas as pd
+        except ImportError:
+            pd = None

         needs_length_check = True

-        if isinstance(new_data, pd.Series | pd.DataFrame):
+        if pd and isinstance(new_data, pd.Series | pd.DataFrame):
             if isinstance(new_data, pd.Series):
                 new_data = new_data.to_frame().T

@@ -574,7 +580,7 @@ class ColumnDataSource(ColumnarDataSource):

         if needs_length_check:
             lengths: set[int] = set()
-            arr_types = (np.ndarray, pd.Series)
+            arr_types = (np.ndarray, pd.Series) if pd else (np.ndarray,)
             for _, x in new_data.items():
                 if isinstance(x, arr_types):
                     if len(x.shape) != 1:
diff --git a/src/bokeh/plotting/_plot.py b/src/bokeh/plotting/_plot.py
index 677a2a8dc..d6d65bc25 100644
--- a/src/bokeh/plotting/_plot.py
+++ b/src/bokeh/plotting/_plot.py
@@ -78,16 +78,19 @@ __all__ = (
 #-----------------------------------------------------------------------------

 def get_range(range_input: Range | tuple[float, float] | Sequence[str] | pd.Series[Any] | GroupBy | None) -> Range:
-    import pandas as pd
-    from pandas.core.groupby import GroupBy
+    try:
+        import pandas as pd
+        from pandas.core.groupby import GroupBy
+    except ImportError:
+        pd = GroupBy = None

     if range_input is None:
         return DataRange1d()
-    if isinstance(range_input, GroupBy):
+    if GroupBy and isinstance(range_input, GroupBy):
         return FactorRange(factors=sorted(list(range_input.groups.keys())))
     if isinstance(range_input, Range):
         return range_input
-    if isinstance(range_input, pd.Series):
+    if pd and isinstance(range_input, pd.Series):
         range_input = range_input.values
     if isinstance(range_input, Sequence | np.ndarray):
         if all(isinstance(x, str) for x in range_input):
diff --git a/src/bokeh/util/serialization.py b/src/bokeh/util/serialization.py
index 27a834c15..655ae63bb 100644
--- a/src/bokeh/util/serialization.py
+++ b/src/bokeh/util/serialization.py
@@ -29,6 +29,7 @@ log = logging.getLogger(__name__)

 # Standard library imports
 import datetime as dt
+import sys
 import uuid
 from functools import lru_cache
 from threading import Lock
@@ -52,19 +53,20 @@ if TYPE_CHECKING:
 #-----------------------------------------------------------------------------

 @lru_cache(None)
-def _compute_datetime_types() -> set[type]:
-    import pandas as pd
+def _compute_datetime_types(pandas_imported) -> set[type]:

     result = {dt.time, dt.datetime, np.datetime64}
-    result.add(pd.Timestamp)
-    result.add(pd.Timedelta)
-    result.add(pd.Period)
-    result.add(type(pd.NaT))
+    if pandas_imported:
+        import pandas as pd
+        result.add(pd.Timestamp)
+        result.add(pd.Timedelta)
+        result.add(pd.Period)
+        result.add(type(pd.NaT))
     return result

 def __getattr__(name: str) -> Any:
     if name == "DATETIME_TYPES":
-        return _compute_datetime_types()
+        return _compute_datetime_types("pandas" in sys.modules)
     raise AttributeError

 BINARY_ARRAY_TYPES = {
@@ -118,7 +120,7 @@ def is_datetime_type(obj: Any) -> TypeGuard[dt.time | dt.datetime | np.datetime6
         bool : True if ``obj`` is a datetime type

     '''
-    _dt_tuple = tuple(_compute_datetime_types())
+    _dt_tuple = tuple(_compute_datetime_types("pandas" in sys.modules))

     return isinstance(obj, _dt_tuple)

@@ -176,22 +178,22 @@ def convert_datetime_type(obj: Any | pd.Timestamp | pd.Timedelta | dt.datetime |
         float : milliseconds

     '''
-    import pandas as pd
+    pd = sys.modules.get("pandas")

     # Pandas NaT
-    if obj is pd.NaT:
+    if pd and obj is pd.NaT:
         return np.nan

     # Pandas Period
-    if isinstance(obj, pd.Period):
+    if pd and isinstance(obj, pd.Period):
         return obj.to_timestamp().value / 10**6.0

     # Pandas Timestamp
-    if isinstance(obj, pd.Timestamp):
+    if pd and isinstance(obj, pd.Timestamp):
         return obj.value / 10**6.0

     # Pandas Timedelta
-    elif isinstance(obj, pd.Timedelta):
+    elif pd and isinstance(obj, pd.Timedelta):
         return obj.value / 10**6.0

     # Datetime (datetime is a subclass of date)
